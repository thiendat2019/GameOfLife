<?xml version="1.0"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="chapter-automated-deployment">
  <title>Automated Deployment and Continuous Delivery</title>
  <sect1 id="sect-continuous-deployment-introduction">
    <title>Introduction</title>
    <para><indexterm class="startofrange" id="ch12-auto1" significance="normal"><primary>automated deployment</primary></indexterm><indexterm class="startofrange" id="ch12-auto2" significance="normal"><primary>continuous deployment</primary></indexterm>CI shouldn't stop once your application
    compiles correctly. Nor should it stop once you can run a set of automated
    tests or automatically check and audit the code for potential quality
    issues. The next logical step, once you've <phrase role="keep-together">achieved</phrase> all of these, is to extend your
    build automation process to the deployment phase. This practice is
    globally known as Automated <phrase role="keep-together">Deployment</phrase> or Continuous <phrase role="keep-together">Deployment</phrase>.</para>
    <para>In its most advanced form, Continuous Deployment is the process
    whereby any code change, subject to automated tests and other appropriate
    verifications, is immediately deployed into production. The aim is to
    reduce cycle time and reduce the time and effort involved in the
    deployment process. This, in turn, helps development teams reduce the time
    it takes to deliver individual features or bug fixes, and, as a consequence,
    significantly increase their throughput. Reducing or eliminating the
    periods of intense activity leading up to a traditional release and
    deployment also frees up time and resources for process improvement and
    innovation. This approach is comparable to the philosophy of continual
    improvement promoted by lean processes such as Kanban.</para>
    <para>Systematically deploying the latest code into production isn't
    always suitable, however, no matter how good your automated tests are.
    Many organizations aren't well prepared for new versions appearing
    unannounced every week; users might need to be trained, products may need
    to be marketed, and so forth. A more conservative variation on this theme,
    often seen in larger organizations, is to have the entire deployment
    process automated but to trigger the actual deployment manually in a
    one-click process. This is known as Continuous Delivery, and it has all
    the advantages of Continuous Deployment without the disadvantages.
    Variations on Continuous Delivery may also involve automatically deploying
    code to certain environments (such as test and QA) while using a manual
    one-click deployment for the other environments (such as UAT and
    Production). The most important distinguishing characteristic of
    Continuous Delivery is that any and every successful build that has passed
    all the relevant automated tests and quality gates can potentially be
    deployed into production via a fully automated one-click process and be in
    the hands of the end-user within minutes. However, the process isn't
    automatic: it's the business, rather than IT, that decides the best time
    to deliver the latest changes.</para>
    <para>Both Continuous Deployment and Continuous Delivery are rightly
    considered to represent a very high level of maturity in terms of build
    automation and SDLC practices. These techniques cannot exist without an
    extremely solid set of automated tests. Nor can they exist without a CI
    environment and a robust build pipeline—indeed it typically represents the
    final stage and goal of the build pipeline. However, considering the
    significant advantages that Continuous Deployment/Delivery can bring to an
    organization, it's a worthy goal. During the remainder of this chapter,
    we'll use the general term of “Continuous Deployment” to refer to both
    Continuous Deployment and Continuous Delivery. Indeed, Continuous Delivery
    can be viewed as Continuous Deployment with the final step (deployment
    into production) being a manual one dictated by the business rather than
    the development team.</para>
  </sect1>
  <sect1 id="sect-implementing-cd">
    <title>Implementing Automated and Continuous Deployment</title>
    <para>In its most elementary form, Automated Deployment can be as simple
    as writing your own scripts to deploy your application to a particular
    server. The main advantage of a scripted solution is simplicity and ease
    of configuration. However, a simple scripted approach may run into limits
    if you need to perform more advanced deployment activities, such as
    installing software on a machine or rebooting the server. For more
    advanced scenarios, you may need to use a more sophisticated
    deployment/configuration management solution such as Puppet or
    Chef.</para>
    <sect2 id="sect-deployment-script">
      <title>The Deployment Script</title>
      <para>An <indexterm id="I_indexterm12_d1e16879" significance="normal"><primary>automated deployment</primary><secondary>deployment script for</secondary></indexterm><indexterm id="I_indexterm12_d1e16884" significance="normal"><primary>continuous deployment</primary><secondary>deployment script for</secondary></indexterm><indexterm id="I_indexterm12_d1e16889" significance="normal"><primary>deployment script</primary></indexterm><indexterm id="I_indexterm12_d1e16892" significance="normal"><primary>scripts</primary><secondary>deployment script</secondary></indexterm>essential part of any Automated Deployment initiative is a
      scriptable deployment process. While this may seem obvious, there are
      still many organizations where deployment remains a cumbersome,
      complicated, and labor-intensive process, including manual file copying,
      manual script execution, hand-written deployment notes, and so forth.
      The good news is that, in general, it doesn't have to be this way.
      With a little work, it's usually possible to write a script of some
      sort to automate most, if not all, of the process.</para>
      <para>The complexity of a deployment script varies enormously from
      application to application. For a simple website, a deployment script
      may be as simple as resyncing a directory on the target server. Many
      Java application servers have Ant or Maven plugins that can be used to
      deploy applications. For a more complicated infrastructure, deployment
      may involve deploying several applications and services across multiple
      <phrase role="keep-together">clustered</phrase> servers in a precisely
      coordinated manner. Most deployment processes tend to fall somewhere
      between these extremes.</para>
    </sect2>
    <sect2 id="sect-liquibase">
      <title>Database Updates</title>
      <para>Deploying<indexterm class="startofrange" id="ch12-db1" significance="normal"><primary>automated deployment</primary><secondary>database updates with</secondary></indexterm><indexterm class="startofrange" id="ch12-db2" significance="normal"><primary>continuous deployment</primary><secondary>database updates with</secondary></indexterm><indexterm class="startofrange" id="ch12-db3" significance="normal"><primary>database</primary><secondary>updating with automated deployment</secondary></indexterm> your app to the application server is often only one part
      of the puzzle. Databases, relational or otherwise, almost always play a
      central role in any application architecture. Of course, ideally, your
      database would be perfect from the start, but this is rarely the case in
      the real world. Indeed, when you update your application, you'll
      generally also need to update one or more databases as well.</para>
      <para>Database updates are usually more difficult to manage smoothly
      than application updates, as both the structure and the contents of the
      database may be impacted. However, managing database updates is a
      critical part of both the development and the deployment process, and
      deserves some reflection and planning.</para>
      <para>Some application frameworks, such as <indexterm id="I_indexterm12_d1e16928" significance="normal"><primary>Ruby on Rails projects</primary></indexterm>Ruby on Rails and <indexterm id="I_indexterm12_d1e16932" significance="normal"><primary>Hibernate, database updates with</primary></indexterm>Hibernate, can manage structural database changes
      automatically to some extent. Using these frameworks, you can typically
      specify if you want to create a new database schema from scratch at each
      update, or whether you want to update the database schema while
      conserving the existing data. While this sounds useful in theory, in
      fact it's very limited for anything other than noncritical development
      environments. In particular, these tools don't handle data migration
      well. For example, if you rename a column in your database, the update
      process will simply create a new column: it won't copy the data from
      the old column into the new column, nor will it remove the old column
      from the updated table.</para>
      <para>Fortunately, this isn't the only approach you can use. Another
      tool that attempts to tackle the thorny problem of database updates is
      <indexterm class="startofrange" id="ch12-liquibase" significance="normal"><primary>Liquibase</primary></indexterm><ulink url="http://www.liquibase.org/">Liquibase</ulink>.
      Liquibase is an open source tool that can help manage and organize
      upgrade paths between versions of a database using a high-level
      approach.</para>
      <para>Liquibase works by keeping a record of database updates applied in
      a table in the database, so that it's easy to bring any target database
      to the correct state for a given version of the application. As a
      result, you don’t need to worry about running the same update script
      twice—Liquibase will only apply the update scripts that haven't already
      been applied to your database. Liquibase is also capable of rolling back
      changes, at least for certain types of changes. However, since this will
      not work for every change (for example, data in a deleted table cannot
      be restored), it's best not to place too much faith in this particular
      feature.</para>
      <para>In Liquibase, you keep track of database changes as a set of
      “change sets,” each of which represents the database update in a
      database-neutral XML format. Change sets can represent any changes you
      would make in a database, from adding and deleting tables, to creating
      or updating columns, indexes, and foreign keys:</para>
      <programlisting id="I_programlisting12_d1e16948" format="linespecific">&lt;databaseChangeLog
xmlns="http://www.liquibase.org/xml/ns/dbchangelog/1.6"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog/1.6
http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-1.6.xsd"&gt;
  &lt;changeSet id="1" author="john"&gt;
    &lt;createTable tableName="department"&gt;
      &lt;column name="id" type="int"&gt;
        &lt;constraints primaryKey="true" nullable="false"/&gt;
      &lt;/column&gt;
      &lt;column name="name" type="varchar(50)"&gt;
        &lt;constraints nullable="false"/&gt;
      &lt;/column&gt;
      &lt;column name="active" type="boolean" defaultValue="1"/&gt;
    &lt;/createTable&gt;
  &lt;/changeSet&gt;
&lt;/databaseChangeLog&gt;</programlisting>
      <para>Change sets can also reflect modifications to existing tables. For
      example, the following change set represents the renaming of a
      column:</para>
      <programlisting id="I_programlisting12_d1e16952" format="linespecific">&lt;changeSet id="1" author="bob"&gt;
  &lt;renameColumn tableName="person" oldColumnName="fname" newColumnName="firstName"/&gt;
&lt;/changeSet&gt;</programlisting>
      <para>Since this representation records the semantic nature of the
      change, Liquibase is capable of handling both the schema updates and
      data migration associated with this change correctly.</para>
      <para>Liquibase can also handle updates to the contents of your
      database, as well as to its structure. For example, the following change
      set inserts a new row of data into a table:</para>
      <programlisting id="I_programlisting12_d1e16959" format="linespecific">&lt;changeSet id="326" author="simon"&gt;
  &lt;insert tableName="country"&gt;
    &lt;column name="id" valueNumeric="1"/&gt;
    &lt;column name="code" value="AL"/&gt;
    &lt;column name="name" value="Albania"/&gt;
  &lt;/addColumn&gt;
&lt;/changeSet&gt;</programlisting>
      <para>Each changeset has an ID and an author, which makes it easier to
      keep track of who made a particular change and reduces the risk of
      conflict. Developers can test their change sets on their own database
      schema, and then commit the change sets to version control when ready. The
      next obvious step is to configure a Jenkins build to run the Liquibase
      updates against the appropriate database automatically before any
      integration tests or application deployment is done, usually as part of
      the ordinary project build script.</para>
      <para>Liquibase integrates well into the build process—it can be
      executed from the command line, or integrated into an Ant or Maven build
      script. Using Maven, for example, you can configure the Maven Liquibase
      Plugin as shown here:</para>
      <programlisting id="I_programlisting12_d1e16965" format="linespecific">&lt;project&gt;
  &lt;build&gt;
    &lt;plugins&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.liquibase&lt;/groupId&gt;
        &lt;artifactId&gt;liquibase-plugin&lt;/artifactId&gt;
        &lt;version&gt;1.9.3.0&lt;/version&gt;
        &lt;configuration&gt;
        &lt;propertyFileWillOverride&gt;true&lt;/propertyFileWillOverride&gt;
        &lt;propertyFile&gt;src/main/resources/liquibase.properties&lt;/propertyFile&gt;
      &lt;/configuration&gt;
    &lt;/plugin&gt;
  &lt;/plugins&gt;
&lt;/build&gt;
...
&lt;/project&gt;</programlisting>
      <para>Using Liquibase with Maven this way, you could update a given
      target database to the current schema using this plugin:</para>
      <screen format="linespecific">$ mvn liquibase:update</screen>
      <para>The default database connection details are specified in the
      <filename moreinfo="none">src/main/resources/liquibase.properties</filename> file,
      and might look something like this:</para>
      <programlisting id="I_programlisting12_d1e16976" format="linespecific">changeLogFile = changelog.xml
driver = com.mysql.jdbc.Driver
url = jdbc:mysql://localhost/ebank
username = scott
password = tiger
verbose = true
dropFirst = false</programlisting>
      <para>However, you can override any of these properties from the command
      line, which makes it easy to set up a Jenkins build to update different
      databases.</para>
      <para>Other similar commands let you generate an SQL script (if you need
      to submit it to your local DBA for approval, for example), or rollback
      to a previous version of the <indexterm id="I_indexterm12_d1e16982" class="endofrange" startref="ch12-liquibase" significance="normal"><primary/></indexterm>schema.</para>
      <para>This is of course just one example of a possible approach. Other
      teams prefer to manually maintain a series of SQL update scripts, or
      write their own in-house solutions. The important thing is to have a
      solution that you can use reliably and reproducibly to update different
      databases to the correct state when deploying your <indexterm id="I_indexterm12_d1e16988" class="endofrange" startref="ch12-db1" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e16990" class="endofrange" startref="ch12-db2" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e16992" class="endofrange" startref="ch12-db3" significance="normal"><primary/></indexterm>applications.</para>
    </sect2>
    <sect2 id="sect-smoke-tests">
      <title>Smoke Tests</title>
      <para>Any <indexterm id="I_indexterm12_d1e17000" significance="normal"><primary>automated deployment</primary><secondary>smoke tests for</secondary></indexterm><indexterm id="I_indexterm12_d1e17005" significance="normal"><primary>continuous deployment</primary><secondary>smoke tests for</secondary></indexterm><indexterm id="I_indexterm12_d1e17010" significance="normal"><primary>smoke tests</primary></indexterm><indexterm id="I_indexterm12_d1e17013" significance="normal"><primary>tests</primary><secondary>smoke tests</secondary></indexterm>serious automated deployment needs to be followed up by a
      series of automated smoke tests. A subset of the automated acceptance
      tests can be a good candidate for smoke tests. Smoke tests should be
      unobtrusive and relatively fast. They should be safe to run in a
      production environment, which may restrict the number of modifications
      the test cases can do in the system.</para>
    </sect2>
    <sect2 id="sect-rolling-back">
      <title>Rolling Back Changes</title>
      <para>Another<indexterm id="I_indexterm12_d1e17024" significance="normal"><primary>automated deployment</primary><secondary>rolling back changes in</secondary></indexterm><indexterm id="I_indexterm12_d1e17029" significance="normal"><primary>continuous deployment</primary><secondary>rolling back changes in</secondary></indexterm> important aspect to consider when setting up Automated
      Deployment is how to back out if something goes wrong, particularly if
      you're thinking of implementing Continuous Deployment. Indeed, it's
      critical to be able to roll back to the previous version if
      required.</para>
      <para>How to do this depends a lot on your application. While it
      is relatively straight-forward to redeploy a previous version of an
      application using Jenkins (we'll look at a technique to do this
      further on in this chapter), the application is often not the only
      player in the game. In particular, you'll need to consider how to
      restore your database to a previous state.</para>
      <para>We <indexterm id="I_indexterm12_d1e17039" significance="normal"><primary>database</primary><secondary>rolling back changes to</secondary></indexterm>saw how it's possible to use Liquibase to manage database
      updates, and, of course, many other strategies are possible. However,
      rolling back a database version presents its own challenges. Liquibase,
      for example, lets you revert some, but not all, changes to the database
      structure. However, data lost (in dropped tables, for example) can't be
      recovered using Liquibase alone.</para>
      <para>The most reliable way to revert your database to a previous state
      is probably to make a backup of the database just before the upgrade,
      and use this backup to restore the database to its previous state. One
      effective strategy is to automate this process in <phrase role="keep-together">Jenkins</phrase> in the deployment build job, and
      then to save both the database backup and the deployable binary file
      as artifacts. This way, you can easily restore the database using the
      saved backup and then redeploy the application using the saved binary.
      We'll look at an example of this strategy in action further on in this
      <indexterm id="I_indexterm12_d1e17050" class="endofrange" startref="ch12-auto1" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17052" class="endofrange" startref="ch12-auto2" significance="normal"><primary/></indexterm>chapter.</para>
    </sect2>
  </sect1>
  <sect1 id="sect-deploying-to-an-app-server">
    <title>Deploying to an Application Server</title>
    <para>Jenkins<indexterm class="startofrange" id="ch12-app1" significance="normal"><primary>automated deployment</primary><secondary sortas="application">to application server</secondary></indexterm><indexterm class="startofrange" id="ch12-app2" significance="normal"><primary>continuous deployment</primary><secondary sortas="application">to application server</secondary></indexterm><indexterm class="startofrange" id="ch12-app3" significance="normal"><primary>application server</primary><secondary>automated deployment to</secondary></indexterm> provides plugins to help you deploy your application to a
    number of commonly-used application servers. The<indexterm id="I_indexterm12_d1e17076" significance="normal"><primary>plugins</primary><secondary>Deploy</secondary></indexterm><indexterm id="I_indexterm12_d1e17081" significance="normal"><primary>Deploy plugin</primary></indexterm> Deploy plugin lets you deploy to Tomcat, JBoss, and
    GlassFish. The<indexterm id="I_indexterm12_d1e17085" significance="normal"><primary>WebSphere Application Server</primary></indexterm><indexterm id="I_indexterm12_d1e17088" significance="normal"><primary>plugins</primary><secondary>Deploy Websphere</secondary></indexterm><indexterm id="I_indexterm12_d1e17093" significance="normal"><primary>Deploy Websphere plugin</primary></indexterm> Deploy Websphere plugin tries to cater to the
    particularities of the IBM WebSphere Application Server.</para>
    <para>For other application servers, you'll typically have to integrate
    the deployment process into your build scripts, or resort to custom
    scripts to deploy your application. For other languages, too, your
    deployment process will vary, but it will often involve some use of shell
    scripting. For example, for a Ruby on Rails application, you may use a
    tool like Capistrano or Chef, or simply a shell script. For a PHP
    application, an FTP or SCP file transfer may suffice.</para>
    <para>Let’s first look at some strategies for deploying your Java
    applications to an application server.</para>
    <para>This is known as a <indexterm id="I_indexterm12_d1e17103" significance="normal"><primary>hot-deploy</primary></indexterm>hot-deploy, where the application is deployed onto a running
    server. This is generally a fast and efficient way of getting your
    application online. However, depending on your application and on your
    application server, this approach has been known to result in memory leaks
    or resource locking issues—older versions of Tomcat, for example, were
    particularly well-known for this. If you run into this sort of issue, you
    may have to force the application to restart after each deployment, or
    possibly schedule a nightly restart of the application server on your test
    machine.</para>
    <sect2 id="sect-deploying-java-app">
      <title>Deploying a Java Application</title>
      <para>In this<indexterm class="startofrange" id="ch12-java1" significance="normal"><primary>Java applications</primary><secondary>deploying to application server</secondary></indexterm><indexterm class="startofrange" id="ch12-java2" significance="normal"><primary>application server</primary><secondary>automated deployment to</secondary><tertiary>Java applications</tertiary></indexterm> section we'll look at an example of how to deploy your
      Java web or <indexterm id="I_indexterm12_d1e17125" significance="normal"><primary>JEE applications</primary><see>Java applications</see></indexterm>JEE application to an application server such as<indexterm class="startofrange" id="ch12-java3" significance="normal"><primary>Tomcat application server</primary><secondary>deploying Java applications to</secondary></indexterm><indexterm class="startofrange" id="ch12-java4" significance="normal"><primary>JBoss application server, deploying Java applications
          to</primary></indexterm><indexterm class="startofrange" id="ch12-java5" significance="normal"><primary>GlassFish application server, deploying Java applications
          to</primary></indexterm> Tomcat, JBoss, or GlassFish.</para>
      <para>One of the fundamental principles of automated deployment is to
      reuse your binaries. It's inefficient, and potentially unreliable, to
      rebuild your application during the deployment process. Indeed, imagine
      that you run a series of unit and integration tests against a particular
      version of your application before deploying it to a test environment
      for further testing. If you rebuild the binary before deploying it to
      the test environment, the source code may have changed since the
      original revision, which means you may not know exactly what you're
      deploying.</para>
      <para>A more efficient process is to reuse the binaries generated by a
      previous build. For example, you may configure a build job to run unit
      and integration tests before generating a deployable binary file
      (typically a WAR or EAR file). You can do this very effectively using
      the<indexterm id="I_indexterm12_d1e17147" significance="normal"><primary>plugins</primary><secondary>Copy Artifact</secondary></indexterm><indexterm id="I_indexterm12_d1e17152" significance="normal"><primary>Copy Artifact plugin</primary></indexterm> Copy Artifact plugin (see <xref linkend="sect-copying-artifacts"/>). This plugin lets you copy an
      artifact from another build job workspace into the current build job
      workspace. This, when combined with a normal build trigger or with
      the<indexterm id="I_indexterm12_d1e17158" significance="normal"><primary>plugins</primary><secondary>Build Promotion</secondary></indexterm><indexterm id="I_indexterm12_d1e17163" significance="normal"><primary>Build Promotion plugin</primary></indexterm> Build Promotion plugin, lets you deploy precisely the
      binary file that you built and tested in the previous phase.</para>
      <para>This approach does put some constraints on the way you build your
      application. In particular, any environment-specific configuration must
      be externalized to the application; JDBC connections or other such
      configuration details shouldn't be defined in configuration files
      embedded in your WAR file, for example, but rather be defined using JDNI
      or in an externalized properties file. If this isn't the case, you may
      need to build from a given SCM revision, as discussed for Subversion in
      <xref linkend="sect-build-from-svn-tag"/>.</para>
      <sect3 id="sect-deploy-plugin">
        <title>Using the Deploy plugin</title>
        <para>If you're<indexterm class="startofrange" id="ch12-plug1" significance="normal"><primary>plugins</primary><secondary>Deploy</secondary></indexterm><indexterm class="startofrange" id="ch12-plug2" significance="normal"><primary>Deploy plugin</primary></indexterm> deploying to a Tomcat, JBoss, or GlassFish server,
        the most useful tool at your disposition will probably be the Deploy
        plugin. This plugin makes it relatively straightforward to integrate
        deployment to these platforms into your Jenkins build process. If you're
        deploying to IBM Websphere, you can use the<indexterm id="I_indexterm12_d1e17185" significance="normal"><primary>WebSphere Application Server</primary></indexterm><indexterm id="I_indexterm12_d1e17188" significance="normal"><primary>plugins</primary><secondary>Deploy Websphere</secondary></indexterm><indexterm id="I_indexterm12_d1e17193" significance="normal"><primary>Deploy Websphere plugin</primary></indexterm> Websphere Deploy plugin to similar ends.</para>
        <para>Let’s see how this plugin works in action, using the simple
        automated build and deployment pipeline illustrated in <xref linkend="fig-cd-pipeline"/>.</para>
        <figure float="0" id="fig-cd-pipeline">
          <title>A simple automated deployment pipeline</title>
          <mediaobject id="I_mediaobject12_d1e17204">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1201.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1201.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>Here, the default build (<command moreinfo="none">gameoflife-default</command>) runs the unit and
        integration tests, and builds a deployable binary in the form of a WAR
        file. The metrics build (<command moreinfo="none">gameoflife-metrics</command>) runs additional checks
        regarding coding standards and code coverage. If both these builds are
        successful, the application will be automatically deployed to the test
        environment by the <command moreinfo="none">gameoflife-deploy-to-test</command> build job.</para>
        <para>In the <emphasis>gameoflife-deploy-to-test</emphasis> build job,
        you use the Copy Artifact plugin to retrieve the WAR file generated in
        the <command moreinfo="none">gameoflife-default</command> build job
        and copies it into the current build job’s workspace (see <xref linkend="fig-jenkins-cd-copy-artifacts"/>).</para>
        <figure float="none" id="fig-jenkins-cd-copy-artifacts">
          <title>Copying the binary artifact to be deployed</title>
          <mediaobject id="I_mediaobject12_d1e17233">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1202.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1202.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>Next, you use the Deploy plugin to deploy the WAR file to the
        test server. Of course, it's generally possible, and not too
        difficult, to write a hand-rolled deployment script to get your
        application on to your application server. In some cases, this may be
        your only option. However, if a Jenkins plugin exists for your
        application server, using it can simplify things considerably. If
        you're deploying to Tomcat, JBoss, or GlassFish, the Deploy plugin
        may work for you. This plugin uses Cargo to connect to your
        application server and deploy (or redeploy) your application. Just
        select the target server type, and specify the server’s URL along with
        the username and password of a user with deployment rights (see <xref linkend="fig-jenkins-cd-deploy-plugin"/>).</para>
        <figure float="0" id="fig-jenkins-cd-deploy-plugin">
          <title>Deploying to Tomcat using the Deploy Plugin</title>
          <mediaobject id="I_mediaobject12_d1e17245">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1203.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1203.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>This is known as a <indexterm id="I_indexterm12_d1e17252" significance="normal"><primary>hot-deploy</primary></indexterm>hot-deploy, where the application is deployed onto a
        running server. This is generally a fast and efficient way of getting
        your application online, and should be the preferred solution because
        of its speed convenience. However, depending on your application and
        on your application server, this approach has been known to result in
        memory leaks or resource locking issues—older versions of Tomcat, for
        example, were particularly well-known for this. If you run into this
        sort of issue, you may have to force the application to restart after
        each deployment, or possibly schedule a nightly restart of the
        application server on your test<indexterm id="I_indexterm12_d1e17256" class="endofrange" startref="ch12-plug1" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17258" class="endofrange" startref="ch12-plug2" significance="normal"><primary/></indexterm> machine.</para>
      </sect3>
      <sect3>
        <title>Redeploying a specific version</title>
        <para>When <indexterm id="I_indexterm12_d1e17266" significance="normal"><primary>Java applications</primary><secondary>redeploying a specific version</secondary></indexterm>you deploy your application automatically or
        continually, it becomes of critical importance to precisely identify
        the version of the application currently deployed. There are several
        ways you can do this, which vary essentially depending on the role Jenkins plays
        in the build/deployment architecture.</para>
        <para>Some teams use Jenkins as the central place of truth, where
        artifacts are both built and stored for future reference. If you store
        your deployable artifacts on Jenkins, then it may make perfect sense
        to deploy your artifacts directly from your Jenkins instance. This isn't
        hard to do: in the next section we'll look at how to do this
        using a combination of the Copy Artifacts, Deploy, and Parameterized
        Trigger plugins.</para>
        <para>Alternatively, if you're using an enterprise repository such as
        Nexus or Artifactory to store your artifacts, then this repository
        should act as the central point of reference: Jenkins should build and
        deploy artifacts to your central repository, and then deploy them from
        there. This is typically the case if you're using Maven as your build
        tool, but teams using tools like Gradle or Ivy may also use this
        approach. Repository managers such as Nexus and Artifactory,
        particularly their commercial editions, make this strategy easier
        to implement by providing features such as build promotion and staging
        repositories that help manage the release state of your
        artifacts.</para>
        <para>Let’s look at how you might implement each of these strategies
        using Jenkins.</para>
      </sect3>
      <sect3>
        <title>Deploying a version from a previous Jenkins build</title>
        <para>Redeploying<indexterm class="startofrange" id="ch12-previous" significance="normal"><primary>Java applications</primary><secondary>redeploying from previous build</secondary></indexterm> a previously-deployed artifact in Jenkins is relatively
        straightforward. In <xref linkend="sect-deploy-plugin"/>, you saw how
        to use the<indexterm id="I_indexterm12_d1e17291" significance="normal"><primary>plugins</primary><secondary>Deploy</secondary></indexterm><indexterm id="I_indexterm12_d1e17296" significance="normal"><primary>Deploy plugin</primary></indexterm><indexterm id="I_indexterm12_d1e17299" significance="normal"><primary>plugins</primary><secondary>Copy Artifact</secondary></indexterm><indexterm id="I_indexterm12_d1e17304" significance="normal"><primary>Copy Artifact plugin</primary></indexterm> Copy Artifacts and Deploy plugins to deploy a WAR file
        built by a previous build job to an application server. What you need
        to do now is to let the user specify the version to be deployed,
        rather than just deploying the latest build.</para>
        <para>We can<indexterm id="I_indexterm12_d1e17310" significance="normal"><primary>plugins</primary><secondary>Parameterized Trigger</secondary></indexterm><indexterm id="I_indexterm12_d1e17315" significance="normal"><primary>Parameterized Trigger plugin</primary></indexterm> do this using the Parameterized Trigger plugin (see
        <xref linkend="sect-advanced-builds-parameterized"/>). First, you add
        a parameter to the build job, using the special “Build selector for
        Copy Artifact” parameter type (see <xref linkend="fig-jenkins-build-selector-copy-artifact"/>).</para>
        <figure float="none" id="fig-jenkins-build-selector-copy-artifact">
          <title>Adding a “Build selector for Copy Artifact” parameter</title>
          <mediaobject id="I_mediaobject12_d1e17326">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1204.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1204.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>This adds a new parameter to your build job (see <xref linkend="fig-jenkins-build-selector-parameter"/>). Here you need to
        enter a name and a short description. The name you provide will be
        used as an environment variable passed to the subsequent build
        steps.</para>
        <figure float="none" id="fig-jenkins-build-selector-parameter">
          <title>Configuring a build selector parameter</title>
          <mediaobject id="I_mediaobject12_d1e17338">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1205.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1205.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>The build selector parameter type lets you pick a previous build
        in a number of ways, including the latest successful build, the
        upstream build that triggered this build job, or a specific build. All
        of these options will be available to the user when he or she triggers
        a build. The Default Selector lets you specify which of these options
        will be proposed by default.</para>
        <para>When the user selects a particular build job, the build number
        will also be stored in the environment variables for use in the build
        steps. The environment variable is called
        <code>COPYARTIFACT_BUILD_NUMBER_</code><replaceable>MY_BUILD_JOB</replaceable>,
        where <replaceable>MY_BUILD_JOB</replaceable> is the name of the
        <phrase role="keep-together">original</phrase> build job (in upper
        case and with characters other than A–Z converted to underscores). For
        example, if you copy an artifact from build number 4 of the
        <emphasis>gameoflife-default</emphasis> project, the
        <code>COPYARTIFACT_BUILD_NUMBER_GAMEOFLIFE_DEFAULT</code> environment
        variable would be set to 4.</para>
        <para>The second part of the configuration is to tell Jenkins what to
        fetch, and from which build job. In the Build section of our project
        configuration, you add a “Copy artifacts from another project” step.
        Here you specify the project where the artifact was built and archived
        (<emphasis>gameoflife-default</emphasis> in our example). You also
        need to make Jenkins use the build specified in the parameter we
        defined earlier. You do this by choosing “Specified by a build
        parameter” in the “Which build” option, and providing the variable
        name you specified earlier in the build selector name field (see <xref linkend="fig-jenkins-copy-artifacts-build-parameter"/>). Then, just
        configure the artifacts to copy as you did in the previous
        example.</para>
        <figure float="none" id="fig-jenkins-copy-artifacts-build-parameter">
          <title>Specify where to find the artifacts to be deployed</title>
          <mediaobject id="I_mediaobject12_d1e17374">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1206.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1206.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>Finally, you deploy the copied artifact using the Deploy plugin,
        as illustrated in <xref linkend="fig-jenkins-cd-deploy-plugin"/>.</para>
        <para>So, let’s see how this build works in practice. When you kick off
        a build manually, Jenkins will propose a list of options letting you
        select the build to redeploy (see <xref linkend="fig-jenkins-redeploy-choose-build"/>).</para>
        <figure float="0" id="fig-jenkins-redeploy-choose-build">
          <title>Choosing the build to redeploy</title>
          <mediaobject id="I_mediaobject12_d1e17391">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1207.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1207.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>Most of these options are fairly self-explanatory.</para>
        <?dbfo-need height=”1in”?>
        <para>The “latest successful build” is the most recent build excluding
        any failing builds. So, this option will typically just redeploy the
        latest version. If you use this option, you'll probably want
        to select the “Stable builds only” checkbox, which will exclude any
        unstable builds as well.</para>
        <para>If you've opted to discard old builds, you'll be able to
        flag certain build jobs to be kept forever (see <xref linkend="sect-general-options"/>). In this case, you can choose to
        deploy the “Latest saved build”.</para>
        <para>A sensible option for an automated build job at the end of a
        build pipeline is “Upstream build that triggered this job”. This way,
        you can be sure that you're deploying the artifact that was generated
        by (or promoted through) the previous build job, even if other builds
        have happened since. It's worth noting that although this sort of
        parameterized build job is often used to manual deploy a specific
        artifact, it can also be effectively used as part of an automated
        build process. If it's not triggered manually, it will simply use
        whatever value you define in the “default selector” field.</para>
        <para>You can also choose the “Specified by permalink” option (see
        <xref linkend="fig-jenkins-build-permalink"/>). This lets you choose
        from a number of shortcut values, such as the last build, the last
        stable build, the last successful build, and so on.</para>
        <figure float="none" id="fig-jenkins-build-permalink">
          <title>Using the “Specified by permalink” option</title>
          <mediaobject id="I_mediaobject12_d1e17414">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1208.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1208.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>However, if you want to redeploy a particular version of your
        application, a more useful option is “Specific build” (see <xref linkend="fig-jenkins-specific-build"/>). This option lets you provide
        a specific build number to be deployed. This is the most flexible way
        to redeploy an application—you'll just need to know the number of
        the build you need to redeploy, but this usually isn’t too hard to
        find by looking at the build history of the original build job.</para>
        <figure float="none" id="fig-jenkins-specific-build">
          <title>Using a specific build</title>
          <mediaobject id="I_mediaobject12_d1e17426">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1209.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1209.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>This is a convenient way to deploy or to redeploy artifacts from
        previous Jenkins build jobs. However, in some cases you may prefer to
        use an artifact stored in an enterprise repository like Nexus or
        Artifactory. We'll look at an example of how to do this in the
        next<indexterm id="I_indexterm12_d1e17434" class="endofrange" startref="ch12-previous" significance="normal"><primary/></indexterm> section.</para>
      </sect3>
      <sect3>
        <title>Deploying a version from a Maven repository</title>
        <para>Many <indexterm class="startofrange" id="ch12-mavenrep" significance="normal"><primary>Java applications</primary><secondary>deploying from Maven repository</secondary></indexterm>organizations use an enterprise repository manager such
        as Nexus and Artifactory to store and share binary artifacts such as
        JAR files. This strategy is commonly used with Maven, but also with
        other build tools such as Ant (with Ivy or the Maven Ant Tasks) and
        Gradle. Using this approach in a CI environment, both snapshot and
        release dependencies are built on your Jenkins server, and then
        deployed to your repository manager (see <xref linkend="fig-jenkins-enterprise-repositories"/>). Whenever a
        developer commits source code changes to the version control system,
        Jenkins will pick up the changes and build new snapshot versions of
        the corresponding artifacts. Jenkins then deploys these snapshot
        artifacts to the local enterprise repository manager, where they can
        be made available to other developers on the team or on other teams
        within the organization. We discussed how to get Jenkins to
        automatically deploy Maven artifacts to an enterprise repository in
        <xref linkend="fig-jenkins-enterprise-repositories"/>. A similar
        approach can also be done using Gradle or Ivy.</para>
        <figure float="0" id="fig-jenkins-enterprise-repositories">
          <title>Using a Maven Enterprise Repository</title>
          <mediaobject id="I_mediaobject12_d1e17455">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1210.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1210.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>Maven conventions use a well-defined system of version numbers,
        distinguishing between SNAPSHOT and RELEASE versions. SNAPSHOT
        versions are considered to be potentially unstable builds of the
        latest code base, whereas RELEASE versions are official releases
        having undergone a more formal release process. Typically, SNAPSHOT
        artifacts are reserved for use within a development team, whereas
        RELEASE versions are considered ready for further testing.</para>
        <para>A similar approach can be used for deployable artifacts such as
        WAR or EAR files—they're built and tested on the CI server, then
        automatically deployed to the enterprise repository, often as part of
        a build pipeline involving automated tests and quality checks (see
        <xref linkend="sect-build-pipelines"/>). SNAPSHOT versions are
        typically deployed to a test server for automated and/or manual
        testing, in order to decide whether a version is ready to be
        officially released.</para>
        <para>The exact strategy used to decide when a release version is to
        be created, and how it's deployed, varies greatly from one
        organization. For example, some teams prefer a formal release at the
        end of each iteration or sprint, with a well-defined version number
        and corresponding set of release notes that's distributed to QA teams
        for further testing. When a particular version gets the go-ahead from
        QA, it can then be deployed into production. Others, using a more lean
        approach, prefer to cut a new release whenever a new feature or bug
        fix is ready to be deployed. If a team is particularly confident in
        their automated tests and code quality checks, it may even be possible
        to automate this process completely, generating and releasing a new
        version either periodically (say every night) or whenever new changes
        are committed.</para>
        <para>There are many ways to implement this sort of strategy. In the
        rest of this section, we'll see how to do it using a conventional
        multimodule Maven project. Our sample project is a web application
        called <command moreinfo="none">gameoflife</command>, consisting of
        three modules: <command moreinfo="none">gameoflife-core</command>,
        <command moreinfo="none">gameoflife-services</command> and <command moreinfo="none">gameoflife-web</command>. The <command moreinfo="none">gameoflife-web</command> module produces a WAR file
        that includes JAR files from the other two modules. It's this WAR
        file that you want to deploy:</para>
        <screen format="linespecific">tuatara:gameoflife johnsmart$ ls -l
total 32
drwxr-xr-x  16 johnsmart  staff    544 16 May 09:58 gameoflife-core
drwxr-xr-x   8 johnsmart  staff    272  4 May 18:12 gameoflife-deploy
drwxr-xr-x   8 johnsmart  staff    272 16 May 09:58 gameoflife-services
drwxr-xr-x  15 johnsmart  staff    510 16 May 09:58 gameoflife-web
-rw-r--r--@  1 johnsmart  staff  12182  4 May 18:07 pom.xml</screen>
        <para>Earlier on in this chapter you saw how to use the Deploy plugin
        to deploy a WAR file generated by the current build job to an
        application server. What you want to do now is to deploy an arbitrary
        version of the WAR file to an application server.</para>
        <para>In <xref linkend="jenkins-maven-releases"/>, we discussed how
        to configure Jenkins to invoke the Maven Release Plugin to generate a
        formal release version of an application. The first step of the
        deployment process starts here, so we'll assume that this has been
        configured and that a few releases have already been deployed to our
        enterprise repository manager.</para>
        <para>The next step involves creating a dedicated project to manage
        the deployment process. This project will be a standard Maven
        project.</para>
        <para>The first thing you need to do is to set up a dedicated
        deployment project. In its simplest form, this project will simply
        fetch the requested version of your WAR file from your enterprise
        repository to be deployed by Jenkins. In the following <filename moreinfo="none">pom.xml</filename> file, you use the <filename moreinfo="none">maven-war-plugin</filename> to fetch a specified
        version of the <command moreinfo="none">gameoflife-web</command> WAR
        file from our enterprise repository. The version you want is specified
        in the <literal moreinfo="none">target.version</literal> <phrase role="keep-together">property</phrase>:</para>
        <programlisting id="I_programlisting12_d1e17513" format="linespecific">&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/
        XMLSchema-instance"
  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://
  maven.apache.org/maven-v4_0_0.xsd"&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;groupId&gt;com.wakaleo.gameoflife&lt;/groupId&gt;
  &lt;artifactId&gt;gameoflife-deploy-with-jenkins&lt;/artifactId&gt;
  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
  &lt;packaging&gt;war&lt;/packaging&gt;
  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;com.wakaleo.gameoflife&lt;/groupId&gt;
      &lt;artifactId&gt;gameoflife-web&lt;/artifactId&gt;
      &lt;type&gt;war&lt;/type&gt;d
      &lt;version&gt;${target.version}&lt;/version&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;
  &lt;build&gt;
    &lt;plugins&gt;
      &lt;plugin&gt;
        &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;
        &lt;configuration&gt;
          &lt;warName&gt;gameoflife&lt;/warName&gt;
          &lt;overlays&gt;
            &lt;overlay&gt;
              &lt;groupId&gt;com.wakaleo.gameoflife&lt;/groupId&gt;
              &lt;artifactId&gt;gameoflife-web&lt;/artifactId&gt;
            &lt;/overlay&gt;
          &lt;/overlays&gt;
        &lt;/configuration&gt;
      &lt;/plugin&gt;
    &lt;/plugins&gt;
  &lt;/build&gt;
  &lt;properties&gt;
    &lt;target.version&gt;RELEASE&lt;/target.version&gt;
  &lt;/properties&gt;
&lt;/project&gt;</programlisting>
        <para>Next, you configure a Jenkins build job to invoke this <filename moreinfo="none">pom.xml</filename> file using a property value
        provided by the user (see <xref linkend="fig-jenkins-gameoflife-deploy"/>). Note that we've set the
        default value to RELEASE so that, by default, the most recent release
        version will be deployed. Otherwise, the user can provide the version
        number of the version to be deployed or <phrase role="keep-together">redeployed</phrase>.</para>
        <figure float="none" id="fig-jenkins-gameoflife-deploy">
          <title>Deploying an artifact from a Maven repository</title>
          <mediaobject id="I_mediaobject12_d1e17528">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1211.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1211.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>The rest of this build job simply checks out the deployment
        project and invokes the <literal moreinfo="none">mvn package</literal> goal, and then
        deploys the WAR file using the Deploy plugin (see <xref linkend="fig-jenkins-mvn-package"/>). The
        <literal moreinfo="none">target.version</literal> property will be automatically
        passed into the build job and used to deploy the correct
        version.</para>
        <figure float="0" id="fig-jenkins-mvn-package">
          <title>Preparing the WAR to be deployed</title>
          <mediaobject id="I_mediaobject12_d1e17546">
            <imageobject role="print">
              <imagedata fileref="figs/print/jtdg_1212.pdf" format="PDF"/>
            </imageobject>
            <imageobject role="web">
              <imagedata fileref="figs/web/jtdg_1212.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>Similar techniques can be used for other project types. If you're
        deploying to an application server that isn't supported by the
        Deploy plugin, you also have the option of writing a custom script in
        whatever language is most convenient, and getting Jenkins to pass the
        requested version number as a parameter as described <indexterm id="I_indexterm12_d1e17553" class="endofrange" startref="ch12-mavenrep" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17555" class="endofrange" startref="ch12-java1" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17557" class="endofrange" startref="ch12-java2" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17559" class="endofrange" startref="ch12-java3" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17561" class="endofrange" startref="ch12-java4" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17563" class="endofrange" startref="ch12-java5" significance="normal"><primary/></indexterm>above.</para>
      </sect3>
    </sect2>
    <sect2>
      <title>Deploying Scripting-based Applications Like Ruby and PHP</title>
      <para>Deploying <indexterm class="startofrange" id="ch12-scripting1" significance="normal"><primary>application server</primary><secondary>automated deployment to</secondary><tertiary>scripting-based applications</tertiary></indexterm><indexterm class="startofrange" id="ch12-scripting2" significance="normal"><primary>Ruby applications</primary></indexterm><indexterm class="startofrange" id="ch12-scripting3" significance="normal"><primary>PHP applications, deploying to application server</primary></indexterm><indexterm class="startofrange" id="ch12-scripting4" significance="normal"><primary>scripting-based applications, deploying to application
          server</primary></indexterm>projects using scripting languages such as PHP and Ruby is
      generally simpler than deploying Java applications, though the issues
      related to database updates are similar. Indeed, very often these
      deployments essentially involve copying files onto a remote server. To
      obtain the files in the first place, you have the choice of either
      copying them from another build job’s workspace using the Copy Artifacts
      option, or checking the source code out directly from the source code
      repository, if necessary using a specific revision or tag as described
      for Subversion in <xref linkend="sect-build-from-svn-tag"/> and for Git
      in <xref linkend="sect-building-git-tag"/>. Then, once you have the
      source code in your Jenkins workspace, you simply need to deploy it onto
      the target server.</para>
      <para>A useful tool for this sort of deployment is the<indexterm id="I_indexterm12_d1e17594" significance="normal"><primary>plugins</primary><secondary>Publish Over</secondary></indexterm><indexterm id="I_indexterm12_d1e17599" significance="normal"><primary>Publish Over plugins</primary></indexterm> Publish Over series of plugins for Jenkins (Publish Over
      FTP, Publish Over SSH, and Publish Over CIFS). These plugins provide a
      consistent and flexible way to deploy your application artifacts to
      other servers over a number of protocols, including CIFS (for Windows
      shared drives), FTP, and SSH/SFTP.</para>
      <para>The configuration for each of these plugins is similar. Once you've
      installed the plugins, you need to set up the host configurations,
      which are managed centrally in the main configuration screen. You can
      create as many host configurations as you like—they'll appear in a
      drop-down list in the job configuration page.</para>
      <para>Configuration of the hosts is fairly self-explanatory (see <xref linkend="fig-jenkins-ssh-config"/>). The name is the name that will
      appear in the drop-down list in the build job configurations. You can
      configure authentication using a username and password for FTP, or
      either an SSH key or a username and password for SSH. You also need to
      provide an existing directory on the remote server that will act at the
      root directory for this configuration. In the Advanced options, you can
      also configure the SSH port and timeout options.</para>
      <figure float="0" id="fig-jenkins-ssh-config">
        <title>Configuring a remote host</title>
        <mediaobject id="I_mediaobject12_d1e17612">
          <imageobject role="print">
            <imagedata fileref="figs/print/jtdg_1213.pdf" format="PDF"/>
          </imageobject>
          <imageobject role="web">
            <imagedata fileref="figs/web/jtdg_1213.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </figure>
      <para>Once you've configured your hosts, you can set up your build
      jobs to deploy artifacts to these hosts. You can do this either as a
      build step (see <xref linkend="fig-jenkins-ssh-build-step"/>) or as a
      post-build action (see <xref linkend="fig-jenkins-ssh-deploy"/>). In
      both cases, the options are similar.</para>
      <figure float="0" id="fig-jenkins-ssh-build-step">
        <title>Deploying files to a remote host in the build section</title>
        <mediaobject id="I_mediaobject12_d1e17626">
          <imageobject role="print">
            <imagedata fileref="figs/print/jtdg_1214.pdf" format="PDF"/>
          </imageobject>
          <imageobject role="web">
            <imagedata fileref="figs/web/jtdg_1214.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </figure>
      <?dbfo-need height=”1in”?>
      <para>First of all, you select the target host from the list of hosts
      you configured in the previous section. Next, you configure the files
      you want to transfer. You do this by defining one or more “Transfer
      sets.” A Transfer set is a set of files (defined by an Ant fileset
      expression) that you deploy to a specified directory on the remote
      server. You can also provide a prefix to be removed—this lets you strip
      off unnecessary directories that you don't want to appear on the server
      (such as the <filename moreinfo="none">target/site</filename> directory
      path in the <phrase role="keep-together">example</phrase>). You can add
      as many transfer sets as you need to get the files you want onto the
      remote server. The plugin also provides options to execute commands on
      the remote server once the transfer is complete (“Exec command”) or to
      exclude certain files or flatten<indexterm id="I_indexterm12_d1e17640" class="endofrange" startref="ch12-scripting1" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17642" class="endofrange" startref="ch12-scripting2" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17644" class="endofrange" startref="ch12-scripting3" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17646" class="endofrange" startref="ch12-scripting4" significance="normal"><primary/></indexterm> the <indexterm id="I_indexterm12_d1e17649" class="endofrange" startref="ch12-app1" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17652" class="endofrange" startref="ch12-app2" significance="normal"><primary/></indexterm><indexterm id="I_indexterm12_d1e17654" class="endofrange" startref="ch12-app3" significance="normal"><primary/></indexterm>directories.</para>
      <figure float="0" id="fig-jenkins-ssh-deploy">
        <title>Deploying files to a remote host in the post-build
        actions</title>
        <mediaobject id="I_mediaobject12_d1e17660">
          <imageobject role="print">
            <imagedata fileref="figs/print/jtdg_1215.pdf" format="PDF"/>
          </imageobject>
          <imageobject role="web">
            <imagedata fileref="figs/web/jtdg_1215.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </figure>
    </sect2>
  </sect1>
  <sect1 id="I_sect112_d1e17665">
    <title>Conclusion</title>
    <para>Automated Deployment, and in its most advanced form, Continuous
    Deployment or Continuous Delivery, can be considered the culminating point
    of a modern CI infrastructure.</para>
    <para>In this chapter we've reviewed several Automated Deployment
    techniques, mostly centered around Java-based deployments. However, the
    general principles discussed here apply for any technology. Indeed, the
    actual deployment process in many other technologies, in particular
    scripting languages such as Ruby and PHP, is considerably simpler than
    when using Java, and essentially involve copying files onto the production
    server. Ruby also benefits from tools such as Heroku and Capistrano to
    facilitate the task.</para>
    <para>There are several important aspects you need to consider when
    setting up an Automated Deployment. First of all, Automated Deployment is
    the end-point of your CI architecture: you need to define a build pipeline
    to take your build from the initial compilation and unit tests, though
    more comprehensive functional and automated acceptance tests and code
    quality checks, culminating in deployment to one or more platforms. The
    degree of confidence you can have in your build pipeline depends largely
    on the degree of confidence you have in your tests. Or, in other words,
    the less reliable and comprehensive your tests, the earlier in the build
    process you'll have to fall back to manual testing and human
    intervention.</para>
    <para>Finally, if at all possible, it's important to build your
    deployable artifact once and once only, and then reuse it in subsequent
    steps for functional tests and deployment to different platforms.</para>
  </sect1>
</chapter>
